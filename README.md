# video_dubbing_ai_2025

## Описание
Платформа для автоматического дубляжа видео с поддержкой zero-shot и few-shot voice cloning, автоматическим ASR, переводом, TTS и анализом качества (similarity).

## Структура каталогов

- data/input/ — исходные видео (input.mp4) и reference-голоса (reference_audio1.wav, ...)
- data/output/ — итоговые видео (с датой/временем в имени)
- data/temp/ — временные файлы (уникальные для каждого запуска, не затираются)
- notebooks/ — ноутбуки с автоматизированными экспериментами
- src/ — исходный код (модули vision_audio, asr, mt, tts, eval и др.)

## Автоматизация экспериментов
- Все этапы (извлечение аудио, ASR, перевод, TTS, сравнение similarity, визуализация) автоматизированы в ноутбуке `notebooks/experiments_automated.ipynb`.
- Временные файлы для каждого запуска создаются в отдельной уникальной папке внутри data/temp.
- Итоговые видео сохраняются в data/output или temp_run_dir с уникальным именем (дата/время).
- Все пути универсальны и работают как из ноутбука, так и из main.py.

## Сценарии экспериментов
1. Zero-shot: дубляж с голосом оригинального спикера (извлечённого из видео)
2. Few-shot: fine-tuning на одном или нескольких reference-голосах, сравнение similarity

## Как использовать
- Поместите input.mp4 и reference_audioX.wav в data/input/
- Запустите основной пайплайн:
  ```bash
  python main.py
  ```
  или через Docker (см. ниже)
- Также доступны эксперименты в ноутбуке `notebooks/experiments_automated.ipynb`
- Результаты появятся в data/output/ или data/temp/...
- Временные файлы для каждого запуска — в data/temp/ (их можно чистить вручную при необходимости)

## Результаты и анализ
- Средние значения similarity и доля успешных сегментов автоматически считаются в ноутбуке.
- Визуализации: line plot, boxplot, pie chart, heatmap (см. ноутбук).
- Итоговые выводы и рекомендации формируются автоматически.

## Запуск в Docker
1. Клонируйте репозиторий:
   ```
   git clone https://github.com/usliders/video-dubbing-ai
   cd video-dubbing-ai
   ```
2. Соберите Docker-образ:
   ```
   docker build -t video-dubbing-ai .
   ```
3. Запустите контейнер для пайплайна (main.py):
   ```
   docker run -it -v $(pwd):/app video-dubbing-ai python main.py
   ```
   или для Jupyter Notebook:
   ```
   docker run -p 8888:8888 -v $(pwd):/app video-dubbing-ai
   ```
4. Следуйте инструкциям в меню main.py или работайте с ноутбуками через http://localhost:8888

**Все зависимости, модели и пайплайн будут работать одинаково на любой машине!**

## Подробнее о коде
См. [src/README.md](src/README.md)

---
_Документация и комментарии — на русском языке для удобства командной работы._ 